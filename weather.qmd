---
title: "A weather-based forecast"
---

```{r include=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, eval=FALSE) # eval=FALSE to omit running
score4cast::ignore_sigpipe()

```


```{r setup}
library(neonstore)
library(neon4cast) # remotes::install_github("eco4cast/neon4cast", dep=TRUE)
library(tidyverse)
library(tsibble)
library(lubridate)
library(fable)
library(glue)
```



```{r}
forecast_date <-  Sys.Date() - days(35)
```

## Access Target Data

The target data is simply a CSV file.  We convert this to a time-series table,
or `tsibble`, by indicating time is indexed by the `datetime` column, with
unique values for each combination of `variable` and `site_id`.

```{r}
targets <-
  glue("https://data.ecoforecast.org/neon4cast-targets/",
       "{theme}/{theme}-targets.csv.gz", theme="aquatics") |> 
  read_csv(show_col_types = FALSE) 

targets_ts <- targets |> 
  pivot_wider(names_from="variable", values_from="observation") |>
  as_tsibble(index = datetime, key = site_id)
```


`fable` requires variables be given as independent columns, so we use `pivot_wider()`.
For illustrative purposes, we will filter out observations more recent than "forecast date".
In a production forecast, obviously this is just the current date and we use all available
data, but then we have to wait a few days before we have new observations to score.

```{r}
past <-  
  targets_ts |> 
  filter(datetime < forecast_date)
```


## Site data



```{r}
site_data <- 
  glue("https://raw.githubusercontent.com/eco4cast/neon4cast-targets/",
                            "main/NEON_Field_Site_Metadata_20220412.csv") |>
  read_csv() |> 
  filter(aquatics == 1) |>
  select(site_id = field_site_id, elevation = field_mean_elevation_m)

```


## Access weather data

We will use downscaled snapshots of NOAA GEFS forecasts at NEON sites.
Note that historical meteorology goes in the `past` data, while forecasted meteorology is passed in as `new_data` to the `forecast` method.

We can use actual NEON weather measurements or NOAA downscaled forecasts sources for historical, past observations.  Note that using NOAA's historical zero-horizon forecast instead of ground-truth measurements can actually be more accurate calibration if future `new_data` forecasts are also coming from NOAA predictions.  (Alternatively, we can merely use historical average seasonal measurements as our long-term 'forecast').





```{r}
sites <- unique(past$site_id)


history <- 
  noaa_stage3() |>
  mutate(date = lubridate::as_date(datetime)) |>
  group_by(site_id, date, variable) |>
  summarise(mean = mean(prediction, na.rm=TRUE),
            .groups = "drop") |>
  filter(site_id %in% sites,
         variable %in% c("air_temperature")) |>
  collect() |>
  pivot_wider(c(site_id, date), names_from="variable", values_from = "mean") |>
  mutate(air_temperature = air_temperature -273) |>
  rename(datetime = date)



```

Join the historical NOAA record of air_temperature by site and datetime

```{r}
past2 <- left_join(past, as_tsibble(history, datetime, key=site_id) ) |> 
  select(temperature, air_temperature, oxygen)  |> 
  left_join(site_data)
```


```{r}
future <- noaa_stage2() |> 
  filter(reference_datetime == lubridate::as_datetime(forecast_date),
         variable %in% c("air_temperature"),
         site_id %in% sites) |>
  mutate(date = lubridate::as_date(datetime)) |>
  group_by(site_id, date, variable) |>
  summarise(mean = mean(prediction, na.rm=TRUE),
            .groups = "drop") |>
  collect() |>
  pivot_wider(c(site_id, date), 
              names_from="variable", 
              values_from = "mean") |>
  mutate(air_temperature = air_temperature -273)  |>
  rename(datetime = date)
```

## Compute a forecast

```{r}
new_data <- future |> as_tsibble(datetime, key=site_id) |> left_join(site_data)
```

```{r}
fc_temperature <- 
  past2  |> 
  select(temperature, air_temperature) |>
  drop_na() |> 
  fill_gaps() |>
  model(tslm = TSLM(temperature ~ air_temperature)) |>
  forecast(new_data = new_data)
```


We can use the mean forecast temperature to drive the oxygen forecast

```{r}

new_data2 <- left_join(new_data, fc_temperature) |> 
  select(site_id, datetime, air_temperature, temperature = .mean)


fc_oxygen <- past2  |> drop_na() |> fill_gaps() |>
  model(tslm = TSLM(oxygen ~ temperature  ) ) |>
  forecast(new_data = new_data2) |>
  select(site_id, datetime, oxygen, .model, .mean)
```

## Visualize the forecast



```{r}
first4 <- unique(fc_temperature$site_id)[1:6]
cutoff <- forecast_date - months(3)
historical <- targets_ts |> filter(datetime > cutoff)

fc_temperature |> filter(site_id %in% first4)  |> 
  autoplot(historical) + ggtitle("temperature")

fc_oxygen |> filter(site_id %in% first4, datetime > cutoff)  |> 
  autoplot(historical) + ggtitle("oxygen")
```


## EFI Formatting

EFI requires a flat-file format for forecasts that avoids the use of complex list columns. To convey uncertainty, forecasts must be expressed either as a parametric distribution (e.g. for predictions that are normally distributed) or must express forecasts as an ensemble of replicate draws from forecast distribution. The helper function `efi_format()` handles this transformation.



```{r}

fc_temperature <- fc_temperature |> select(-air_temperature, -elevation)

forecast <- bind_rows(efi_format(fc_temperature), 
                      efi_format(fc_oxygen))  |>
            mutate(reference_datetime = forecast_date)

```


```{r}
scores <- score(forecast, targets)
fable_score <- scores |> 
  score4cast::include_horizon(allow_difftime = TRUE) |> 
  group_by(variable) |>
  summarise(crps = mean(crps, na.rm=TRUE), 
            logs = mean(logs, na.rm=TRUE))
fable_score
```


```{r}
forecast_file <- glue::glue("{theme}-{date}-{team}.csv.gz",
                            theme = "aquatics", 
                            date=forecast_date,
                            team = "cb_weather")
write_csv(forecast, forecast_file)
```


```{r}
neon4cast::forecast_output_validator(forecast_file)
```


```{r}
submit(forecast_file)
```


```{r}
unlink(forecast_file)
```

